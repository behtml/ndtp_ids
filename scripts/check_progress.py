#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–±–æ—Ä–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
- –°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω —Å–æ–±—Ä–∞–Ω–æ
- –°–∫–æ–ª—å–∫–æ —Ö–æ—Å—Ç–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
- –°–∫–æ–ª—å–∫–æ ML training samples –≥–æ—Ç–æ–≤–æ
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –æ–±—É—á–µ–Ω–∏—é ML-–º–æ–¥–µ–ª–∏

–ó–∞–ø—É—Å–∫:
    python scripts/check_progress.py
    python scripts/check_progress.py --db my_ids.db
"""
import os
import sys
import sqlite3
import argparse
from datetime import datetime

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


def check_progress(db_path: str = "ids.db"):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""

    if not os.path.exists(db_path):
        print(f"[!] –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        print("    –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —Å–Ω–∞—á–∞–ª–∞ ‚Äî —Å–º. scripts/run_all.py")
        return

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    print("=" * 55)
    print("–ü–†–û–ì–†–ï–°–° –°–ë–û–†–ê –î–ê–ù–ù–´–•")
    print("=" * 55)

    # 1. –û–±—â–∏–µ —Å–æ–±—ã—Ç–∏—è
    try:
        cursor.execute("SELECT COUNT(*) FROM raw_events")
        total_events = cursor.fetchone()[0]
    except Exception:
        total_events = 0

    print(f"\n  –°—ã—Ä—ã—Ö —Å–æ–±—ã—Ç–∏–π (–ø–∞–∫–µ—Ç–æ–≤): {total_events}")

    # 2. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞
    try:
        cursor.execute("SELECT COUNT(DISTINCT window_start) FROM aggregated_metrics")
        total_windows = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(DISTINCT src_ip) FROM aggregated_metrics")
        total_hosts = cursor.fetchone()[0]

        cursor.execute("""
            SELECT MIN(datetime(window_start, 'unixepoch', 'localtime')),
                   MAX(datetime(window_end, 'unixepoch', 'localtime'))
            FROM aggregated_metrics
        """)
        time_range = cursor.fetchone()
    except Exception:
        total_windows = 0
        total_hosts = 0
        time_range = (None, None)

    print(f"  –í—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω:          {total_windows}")
    print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤:       {total_hosts}")
    if time_range[0]:
        print(f"  –ü–µ—Ä–∏–æ–¥:                  {time_range[0]} ‚Äî {time_range[1]}")

    # 3. ML training data
    ml_samples = 0
    ml_min_required = 50
    try:
        cursor.execute("SELECT COUNT(*) FROM ml_training_data WHERE is_normal = 1")
        ml_samples = cursor.fetchone()[0]
    except Exception:
        pass

    print(f"\n  ML training samples:     {ml_samples} / {ml_min_required}")

    # –ü–æ–ª–æ—Å–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    pct = min(100, int(ml_samples / ml_min_required * 100))
    bar_len = 30
    filled = int(bar_len * pct / 100)
    bar = "‚ñà" * filled + "‚ñë" * (bar_len - filled)
    print(f"  –ü—Ä–æ–≥—Ä–µ—Å—Å:  [{bar}] {pct}%")

    ready = ml_samples >= ml_min_required
    if ready:
        print(f"\n  ‚úÖ –ì–û–¢–û–í–û –ö –û–ë–£–ß–ï–ù–ò–Æ ML!")
        print(f"     –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/train_model.py")
        print(f"     –∏–ª–∏ —á–µ—Ä–µ–∑ –≤–µ–±: http://127.0.0.1:5000/training ‚Üí ¬´–û–±—É—á–∏—Ç—å¬ª")
    else:
        remaining = ml_min_required - ml_samples
        print(f"\n  ‚è≥ –ï—â—ë –Ω—É–∂–Ω–æ: {remaining} samples")
        print(f"     –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–±–æ—Ç—É, –ø–æ–∫–∞ –ø–∞–∫–µ—Ç–Ω—ã–π –∫–æ–ª–ª–µ–∫—Ç–æ—Ä –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Ç—Ä–∞—Ñ–∏–∫")

    # 4. –ü—Ä–æ—Ñ–∏–ª–∏ —Ö–æ—Å—Ç–æ–≤
    try:
        cursor.execute("SELECT src_ip, is_learning, samples_count FROM host_profiles")
        profiles = cursor.fetchall()
        if profiles:
            print(f"\n  –ü—Ä–æ—Ñ–∏–ª–∏ —Ö–æ—Å—Ç–æ–≤:")
            for ip, learning, samples in profiles:
                mode = "üü° –æ–±—É—á–µ–Ω–∏–µ" if learning else "üü¢ –¥–µ—Ç–µ–∫—Ü–∏—è"
                print(f"    {ip:20s} {mode}  ({samples} samples)")
    except Exception:
        pass

    # 5. –ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    try:
        cursor.execute("""
            SELECT src_ip, metric_name, metric_value,
                   datetime(timestamp, 'unixepoch', 'localtime') as time
            FROM aggregated_metrics
            ORDER BY timestamp DESC
            LIMIT 10
        """)
        recent = cursor.fetchall()
        if recent:
            print(f"\n  –ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏:")
            for row in recent:
                print(f"    {row[3]} | {row[0]:15s} | {row[1]:20s} = {row[2]:.1f}")
    except Exception:
        pass

    # 6. –ê–ª–µ—Ä—Ç—ã
    try:
        cursor.execute("SELECT COUNT(*) FROM alerts")
        total_alerts = cursor.fetchone()[0]
        print(f"\n  –í—Å–µ–≥–æ –∞–ª–µ—Ä—Ç–æ–≤ (z-score): {total_alerts}")
    except Exception:
        pass

    try:
        cursor.execute("SELECT COUNT(*) FROM ml_alerts")
        ml_alerts = cursor.fetchone()[0]
        print(f"  –í—Å–µ–≥–æ –∞–ª–µ—Ä—Ç–æ–≤ (ML):      {ml_alerts}")
    except Exception:
        pass

    print("=" * 55)
    conn.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö NDTP IDS")
    parser.add_argument("--db", default="ids.db", help="–ü—É—Ç—å –∫ –ë–î (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ids.db)")
    args = parser.parse_args()

    os.chdir(PROJECT_ROOT)
    check_progress(db_path=args.db)
